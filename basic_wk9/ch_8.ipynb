{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순환 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 순환 신경망: 시퀸스 단위로 처리하는 스퀀스 모델\n",
    "# 입력과 출력의 길이를 다르게 설계할 수 있음.\n",
    "# RNN 셀의 각 입, 출력단위는 주로 단어 벡터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SimpleRNN.__init__() missing 1 required positional argument: 'units'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\STUDY\\방학(4)\\Prometheus-ML\\basic_wk9\\ch_8.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/%EB%B0%A9%ED%95%99%284%29/Prometheus-ML/basic_wk9/ch_8.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m SimpleRNN\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/STUDY/%EB%B0%A9%ED%95%99%284%29/Prometheus-ML/basic_wk9/ch_8.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m SimpleRNN()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/STUDY/%EB%B0%A9%ED%95%99%284%29/Prometheus-ML/basic_wk9/ch_8.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39madd(SimpleRNN(hidden_units))\n",
      "\u001b[1;31mTypeError\u001b[0m: SimpleRNN.__init__() missing 1 required positional argument: 'units'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "model = SimpleRNN()\n",
    "model.add(SimpleRNN(hidden_units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN 층은 사용자의 설정에 따라 두 가지 종류의 출력\n",
    "#! 메모리 셀의 최종 시점의 은닉 상태만을 리턴하고자 한다면 (batch_size, output_dim) 크기의 2D 텐서를 리턴합니다. 하지만, 메모리 셀의 각 시점(time step)의 은닉 상태값들을 모아서 전체 시퀀스를 리턴하고자 한다면 (batch_size, timesteps, output_dim) 크기의 3D 텐서를 리턴합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, input_shape=(2, 10)))\n",
    "# model.add(SimpleRNN(3, input_length=2, input_dim=10))와 동일함.\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_1 (SimpleRNN)    (8, 3)                    42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 2D 텐서\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10)))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn_2 (SimpleRNN)    (8, 2, 3)                 42        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42\n",
      "Trainable params: 42\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 3D 텐서\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(3, batch_input_shape=(8, 2, 10), return_sequences=True))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "초기 은닉 상태 : [0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 파이썬으로 RNN구현하기\n",
    "import numpy as np\n",
    "\n",
    "timesteps = 10\n",
    "input_dim = 4\n",
    "hidden_units = 8\n",
    "\n",
    "# 입력에 해당되는 2D 텐서\n",
    "inputs = np.random.random((timesteps, input_dim))\n",
    "\n",
    "# 초기 은닉 상태는 0(벡터)로 초기화\n",
    "hidden_state_t = np.zeros((hidden_units,)) \n",
    "\n",
    "print('초기 은닉 상태 :',hidden_state_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가중치 Wx의 크기(shape) : (8, 4)\n",
      "가중치 Wh의 크기(shape) : (8, 8)\n",
      "편향의 크기(shape) : (8,)\n"
     ]
    }
   ],
   "source": [
    "Wx = np.random.random((hidden_units, input_dim))  # (8, 4)크기의 2D 텐서 생성. 입력에 대한 가중치.\n",
    "Wh = np.random.random((hidden_units, hidden_units)) # (8, 8)크기의 2D 텐서 생성. 은닉 상태에 대한 가중치.\n",
    "b = np.random.random((hidden_units,)) # (8,)크기의 1D 텐서 생성. 이 값은 편향(bias).\n",
    "\n",
    "print('가중치 Wx의 크기(shape) :',np.shape(Wx))\n",
    "print('가중치 Wh의 크기(shape) :',np.shape(Wh))\n",
    "print('편향의 크기(shape) :',np.shape(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 시점의 은닉 상태 :\n",
      "[[0.87504622 0.51508439 0.41045536 0.79560342 0.82928792 0.91611041\n",
      "  0.80202252 0.80237324]\n",
      " [0.99995244 0.99921677 0.99960384 0.99498194 0.99803617 0.99987055\n",
      "  0.99936662 0.99930641]\n",
      " [0.99999841 0.99995077 0.99994523 0.99899945 0.99956907 0.99998127\n",
      "  0.99996825 0.99992396]\n",
      " [0.99999842 0.99997221 0.99996074 0.9988597  0.99963746 0.99998593\n",
      "  0.9999817  0.99994916]\n",
      " [0.99999842 0.99993973 0.99993489 0.99933073 0.99961959 0.99998269\n",
      "  0.99995306 0.99990725]\n",
      " [0.99999773 0.99996971 0.99994069 0.99919838 0.99968058 0.99997238\n",
      "  0.99994635 0.99989729]\n",
      " [0.99999938 0.99998675 0.99997047 0.99967983 0.99991442 0.99999302\n",
      "  0.99998264 0.99996363]\n",
      " [0.99999911 0.99997191 0.99994431 0.99957514 0.99985539 0.99997365\n",
      "  0.99994006 0.99990079]\n",
      " [0.99999644 0.99995556 0.99993289 0.99875773 0.9993927  0.99997079\n",
      "  0.99994791 0.99988885]\n",
      " [0.99999937 0.99996834 0.99996569 0.99932391 0.99978992 0.99999126\n",
      "  0.99998592 0.99996149]]\n"
     ]
    }
   ],
   "source": [
    "total_hidden_states = []\n",
    "\n",
    "# 각 시점 별 입력값.\n",
    "for input_t in inputs:\n",
    "\n",
    "  # Wx * Xt + Wh * Ht-1 + b(bias)\n",
    "  output_t = np.tanh(np.dot(Wx, input_t) + np.dot(Wh, hidden_state_t) + b)\n",
    "\n",
    "  # 각 시점 t별 메모리 셀의 출력의 크기는 (timestep t, output_dim)\n",
    "  # 각 시점의 은닉 상태의 값을 계속해서 누적\n",
    "  total_hidden_states.append(list(output_t))\n",
    "  hidden_state_t = output_t\n",
    "\n",
    "# 출력 시 값을 깔끔하게 해주는 용도.\n",
    "total_hidden_states = np.stack(total_hidden_states, axis=0)\n",
    "\n",
    "# (timesteps, output_dim)\n",
    "print('모든 시점의 은닉 상태 :')\n",
    "print(total_hidden_states)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 깊은 순환 신경망: 은닉층이 2개 이상인 신경망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 양방향 순환 신경망: Forward State, Backward State"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 장단기 메모리(LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 바닐라 RNN\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35e0334895c7257ffa902a82750dbe09ec85e290cbc1321a3819ebf1c9410545"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
